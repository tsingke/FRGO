# Flexible reshuffling evolution operators for complex optimization


**Abstract**：Global optimization performance in evolutionary algorithms (EAs) is critically dependent on the effectiveness and efficiency of search operators.  Traditional EAs typically employ predefined single, multiple, or hybrid operators that remain static throughout the execution, which constrains their ability to adapt to complex and dynamic search landscapes, thereby limiting their effectiveness in solving intricate optimization problems.  To overcome this limitation, we propose the Flexible Reshuffling Growth Optimizer (FRGO), a novel method that employs a variable adaptive generative operators construction approach. This method utilizes a fine-grained combinatorial shuffling technique to dynamically generate a diverse set of elementary operators from a finite evoltion pool, enabling real-time adaptation to evolving search environments. By allowing the mathematical expression of operators to evolve randomly, FRGO significantly enhances the likelihood of achieving superior solutions compared to static, predefined operators. The algorithm integrates three core components: a learning operator that flexibly reshuffles its mathematical model to adapt to diverse fitness landscapes, a reflection operator that converts differences between Gaussian distribution models into sample differences for enhanced exploration, and a dynamic population partitioning strategy that supports effective sampling. The robustness and efficacy of FRGO are validated through component validity tests and search behavior analysis. Numerical simulations on the CEC2017, CEC2019, and CEC2022 benchmark suites demonstrate that FRGO outperforms nine advanced differential evolution and particle swarm optimization variants, nine novel metaheuristics, and seven state-of-the-art CEC competition winners, particularly in terms of global convergence capability and computational efficiency. The FRGO algorithm’s source code is publicly available at https://github.com/tsingke/FRGO.


*Note:* This research is currently under preparation for submission as a manuscript. Copyright of the work resides with the authors and is provided here for educational purposes only.
